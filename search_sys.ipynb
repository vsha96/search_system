{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "024f4a67",
   "metadata": {},
   "source": [
    "# Поиск по коллекции (из фактов Википедии)\n",
    "Шулюгин Иван МГУ ВМК 425  \n",
    "Октябрь 2021 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f9cde9",
   "metadata": {},
   "source": [
    "## Описание\n",
    "В данном отчете подробно разобраны шаги для создания примитивной поисковой системы, использующей в своей основе векторное представление документов, где значения рассчитываются через tf_idf (двумя способами подсчета tf: count и log(1+count))  \n",
    "\n",
    "Здесь документы - это предложения из коллекции текстов  \n",
    "Тексты взяты из прикрепленных ссылок к интересным фактам Википедии  \n",
    "Запросы - сами формулировку этих фактов (можно увидеть в частях **Запросы** и **Поиск по запросу**)  \n",
    "\n",
    "При поиске по запросу, сам запрос тоже переводится в векторное пространство документов, и система выдает релевантные документы по мере их близости (близость считается как cos между векторами)  \n",
    "  \n",
    "  \n",
    "### Некоторые ключевые моменты и удобные возможности:\n",
    "- Даты, римские цифры, английские названия - тоже термы (это может играть роль при поиске документа)  \n",
    "- Есть возможность сохранять или пересобирать коллекцию с помощью make_collection()  \n",
    "- Автоматическое добавление новых текстов в коллекцию (нужно записывать новые факты в виде fact_*\\<number>*.txt в директорию text и перезапустить сборку коллекции)  \n",
    "- Обработанная коллекция сохраняется и подгружается как объект pickle (в директории obj)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34267b78",
   "metadata": {},
   "source": [
    "## Необходимые модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4596a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a299fa",
   "metadata": {},
   "source": [
    "Для обработки русских предложений, может понадобиться установить сначала токенайзер русского языка."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db39434",
   "metadata": {},
   "source": [
    "```\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e5ad8f",
   "metadata": {},
   "source": [
    "## Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133badb",
   "metadata": {},
   "source": [
    "Запросы – это проанализированные факты из Википедии  \n",
    "\n",
    "• Коллекция собирается из всех упомянутых статей, из всех фактов  \n",
    "• Документы – это предложения из статей Википедии, указанных в этих фактах, т.е. коллекция – это объединенная коллекция предложений статей всех фактов  \n",
    "\n",
    "• Все должно быть обработано морфологическим анализатором  \n",
    "\n",
    "• Нужно найти наиболее релевантные предложения  \n",
    "– По tf.idf (df в данном случае – это количество предложений, в которых встречалось слово)  \n",
    "– Tf –  \n",
    "    • 1) это количество упоминаний слова в предложении (count) или  \n",
    "    • 2) log (1+count)  \n",
    "– Нормализация запроса и предложения  \n",
    "– Выстроить все предложения из статей по мере сходства с запросом по векторной модели.  \n",
    "– В отчете должны быть показаны веса выдаваемых предложений  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb604c94",
   "metadata": {},
   "source": [
    "## Запросы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515d03d",
   "metadata": {},
   "source": [
    "1) Верный королю барон в награду был назначен опекуном дочери мятежника и женил на ней своего сына  \n",
    "2) К началу ХХ века на складе казенного чугуноплавильного завода скопился годовой запас продукции  \n",
    "3) Лагерь сапёров мог стать важнейшим городом Британской Колумбии  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37753b",
   "metadata": {},
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88a26f",
   "metadata": {},
   "source": [
    "### Разбиение текста на предложения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69f7f4",
   "metadata": {},
   "source": [
    "Собираем текст из всех фактов (тексты записаны в файлах **fact_*i*.txt** в исходной директории)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52038c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_text():\n",
    "    reg_file = r'fact_\\d.txt'\n",
    "\n",
    "    file_list = []\n",
    "\n",
    "    for file_name in sorted(os.listdir('text')):\n",
    "        if re.match(reg_file, file_name):\n",
    "            file_list.append('text/'+file_name)\n",
    "\n",
    "    if file_list == []:\n",
    "        print(\"there are no text files\")\n",
    "\n",
    "    all_text = \"\"\n",
    "\n",
    "    for file_name in file_list:\n",
    "        with open(file_name) as file:\n",
    "            print(\"open\", file_name)\n",
    "            all_text = all_text + file.read()\n",
    "    print(\"done!\")\n",
    "\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1940718f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open text/fact_1.txt\n",
      "open text/fact_2.txt\n",
      "open text/fact_3.txt\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "all_text = collect_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be87407",
   "metadata": {},
   "source": [
    "Разбиваем текст на предложения с помощью токенайзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23b88bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_list(text):\n",
    "    proc_text = []\n",
    "\n",
    "    for el in text.split('\\n'):\n",
    "        if el:\n",
    "            sent_list = sent_tokenize(el, language=\"russian\")\n",
    "            for s in sent_list:\n",
    "                proc_text.append(s)\n",
    "    return proc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e6538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_text = sentence_list(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4dc4782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Генрих III (1 октября 1207, Уинчестер — 16 ноября 1272, Вестминстер) — король Англии (1216—1272) и герцог Аквитании из династии Плантагенетов, один из самых малоизвестных британских монархов, при том что правил он дольше всех прочих средневековых королей Англии — 56 лет.',\n",
       " 'Ранние годы.',\n",
       " 'Генрих родился 1 октября 1207 года в Уинчестерском замке.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25d938",
   "metadata": {},
   "source": [
    "### Сбор термов, подсчет idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6349129",
   "metadata": {},
   "source": [
    "Регулярное выражение и функция лемматизации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6adadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# кроме русских слов оставим еще даты, а также английские названия,\n",
    "#   тем самым оставив римские цифры (e.g. III = 3, IV = 4)\n",
    "reg_filter = r'[а-яА-Я]|[a-zA-Z]|\\d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a29e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "english_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "def process_text(text):    \n",
    "    tokens = mystem.lemmatize(text)\n",
    "    tokens = [token.lower() \n",
    "              for token in tokens \n",
    "              if token not in russian_stopwords \n",
    "              and token not in english_stopwords\n",
    "              and token != \" \"\n",
    "              and re.match(reg_filter, token) ]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8776fd2",
   "metadata": {},
   "source": [
    "Теперь лемматизируем каждое предложение из **proc_text**, удаляем стоп-слова, проверяем на соответствие регулярному выражению заносим уже термы в словарь термов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5b3746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = {}\n",
    "term_text = []\n",
    "\n",
    "for sentence in proc_text:\n",
    "    new_terms = process_text(sentence)\n",
    "    term_text.append(new_terms)\n",
    "    \n",
    "    for t in new_terms:\n",
    "        if t not in terms:\n",
    "            terms[t] = {'df': None, 'idf': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc39c6dc",
   "metadata": {},
   "source": [
    "Определяем df для каждого терма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d54829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in terms:\n",
    "    terms[t]['df'] = 0\n",
    "    for doc in term_text:\n",
    "        if t in doc:\n",
    "            terms[t]['df'] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc3458e",
   "metadata": {},
   "source": [
    "Считаем idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b2027ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_docs = len(proc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1ad8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in terms:\n",
    "    terms[t]['idf'] = np.log10(number_of_docs / terms[t]['df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29ce3d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "генрих {'df': 55, 'idf': 1.0348835702459926}\n",
      "iii {'df': 24, 'idf': 1.3950350180286304}\n",
      "1 {'df': 20, 'idf': 1.4742162640762553}\n"
     ]
    }
   ],
   "source": [
    "# посмотрим, что получилось\n",
    "for i in range(3):\n",
    "    t = list(terms.keys())[i]\n",
    "    print(t, terms[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cd03d1",
   "metadata": {},
   "source": [
    "То есть здесь, в конечном итоге, функция выглядит так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "685db3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_terms(proc_text):\n",
    "    terms = {}\n",
    "    term_text = []\n",
    "\n",
    "    for sentence in proc_text:\n",
    "        new_terms = process_text(sentence)\n",
    "        term_text.append(new_terms)\n",
    "\n",
    "        for t in new_terms:\n",
    "            if t not in terms:\n",
    "                terms[t] = {'df': None, 'idf': None}\n",
    "                \n",
    "    for t in terms:\n",
    "        terms[t]['df'] = 0\n",
    "        for doc in term_text:\n",
    "            if t in doc:\n",
    "                terms[t]['df'] += 1\n",
    "    \n",
    "    number_of_docs = len(proc_text)\n",
    "    for t in terms:\n",
    "        terms[t]['idf'] = np.log10(number_of_docs / terms[t]['df'])\n",
    "    \n",
    "    return terms, term_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a926325",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms, term_text = make_terms(proc_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad835ea",
   "metadata": {},
   "source": [
    "### Отображение исходного предложения в вектор пространства термов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b7e387",
   "metadata": {},
   "source": [
    "Функция нормализации вектора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d8ebd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(vec):\n",
    "    norm = np.linalg.norm(vec)\n",
    "    return vec/norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d14a8",
   "metadata": {},
   "source": [
    "Функция представления вектора в пространстве термов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4029b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_vec(doc, terms):\n",
    "    words = list(terms.keys())\n",
    "    doc_vec = np.zeros(len(terms.keys()))\n",
    "\n",
    "    for t in doc:\n",
    "        if t in words:\n",
    "            i = words.index(t)\n",
    "            doc_vec[i] += 1\n",
    "        else:\n",
    "            print(\"WARN: query word {\" + t + \"} is not in the collection\")\n",
    "        \n",
    "    return doc_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7641bc",
   "metadata": {},
   "source": [
    "Функция взвешенного вектора документа (выдает два ответа, соответственно двум разным способам учета tf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f93280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_tf_idf_vec(doc, terms):\n",
    "    words = terms.keys()\n",
    "    w_vec = np.zeros(len(terms.keys()))\n",
    "    \n",
    "    doc_vec_tf1 = tf_vec(doc, terms)\n",
    "    doc_vec_tf2 = tf_vec(doc, terms)\n",
    "    #print(\"doc = \", doc, \"\\ndoc_vec after tf_vec():\\n\", doc_vec_tf1, \"\\n\")\n",
    "    \n",
    "    i = 0\n",
    "    for word in words:\n",
    "        doc_vec_tf1[i] *= terms[word]['idf']\n",
    "        doc_vec_tf2[i] = np.log(1+doc_vec_tf2[i]) * terms[word]['idf']\n",
    "        i += 1\n",
    "    \n",
    "    return (doc_vec_tf1, doc_vec_tf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89358e7b",
   "metadata": {},
   "source": [
    "На этом моменте у нас есть два списка: исходные предложения **proc_text** и списки термов каждого предложения **term_text**  \n",
    "  \n",
    "Для каждого документа из **proc_text** построим векторы по его представлению в **term_text** и запишем их вместе  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd5880bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_collection = list(zip(proc_text, [weight_tf_idf_vec(sent, terms) for sent in term_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8ade2",
   "metadata": {},
   "source": [
    "Осталось теперь найти релевантные документы из данной коллекции для запроса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b12406",
   "metadata": {},
   "source": [
    "Функция сборки коллекции (сохраняет объект pickle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46a7461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_collection():\n",
    "    print(\"building collection...\")\n",
    "    all_text = collect_text()\n",
    "    proc_text = sentence_list(all_text)\n",
    "    terms, term_text = make_terms(proc_text)\n",
    "    proc_collection = list(zip(proc_text, [weight_tf_idf_vec(sent, terms) for sent in term_text]))\n",
    "    if 'obj' not in os.listdir():\n",
    "        os.mkdir('obj')\n",
    "    with open('obj/core_collection.pkl','wb') as f:\n",
    "        pickle.dump(proc_collection, f, pickle.HIGHEST_PROTOCOL)\n",
    "    with open('obj/terms.pkl','wb') as f:\n",
    "        pickle.dump(terms, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da0d975",
   "metadata": {},
   "source": [
    "Функция подсчета близости документов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b372138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(vec1, vec2):\n",
    "    cos = np.dot(normalize(vec1), normalize(vec2))\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d5982",
   "metadata": {},
   "source": [
    "**Функция поиска по коллекции (выдает документы со значениями по мере их релевантности):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6fdeb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    obj_name = 'core_collection.pkl'\n",
    "    if 'obj' not in os.listdir() or obj_name not in os.listdir('obj'):\n",
    "        make_collection()\n",
    "\n",
    "    with open('obj/'+obj_name,'rb') as f:\n",
    "        proc_collection = pickle.load(f)\n",
    "    with open('obj/terms.pkl','rb') as f:\n",
    "        terms = pickle.load(f)\n",
    "\n",
    "    vec_q = normalize(tf_vec(process_text(query), terms))\n",
    "\n",
    "    rel_docs1 = []\n",
    "    rel_docs2 = []\n",
    "    \n",
    "    for i in range(len(proc_collection)):\n",
    "        vec_d1 = proc_collection[i][1][0] # вектор по подсчету tf = count\n",
    "        vec_d2 = proc_collection[i][1][1] # вектор по подсчету tf = log(1+count)\n",
    "        \n",
    "        rel_docs1.append((proc_collection[i][0], similarity(vec_q, vec_d1)))\n",
    "        rel_docs2.append((proc_collection[i][0], similarity(vec_q, vec_d2)))\n",
    "                         \n",
    "    rel_docs1.sort(key=lambda x:x[1], reverse=True)\n",
    "    rel_docs2.sort(key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "    return rel_docs1, rel_docs2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bdcf66",
   "metadata": {},
   "source": [
    "### Поиск по запросу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a6f04f",
   "metadata": {},
   "source": [
    "1) Верный королю барон в награду был назначен опекуном дочери мятежника и женил на ней своего сына  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33b9528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: query word {награда} is not in the collection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Опека над другой дочерью Випонта, Идонеей, была поручена Роджеру Лейбёрну, женившего на ней своего сына.',\n",
       "  0.3497588024421523),\n",
       " ('Кроме того, Клиффорду была поручена опека над Изабеллой, одной из дочерей мятежного барона Роберта де Випонта, на которой он женил своего наследника.',\n",
       "  0.3080062523852433),\n",
       " ('На ближайшие семь лет опекунами короля были назначены сторонники Дорварда, причем сместить их мог только король Англии.',\n",
       "  0.2687454450045788)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('Верный королю барон в награду был назначен опекуном дочери мятежника и женил на ней своего сына')[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5262c9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: query word {награда} is not in the collection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Опека над другой дочерью Випонта, Идонеей, была поручена Роджеру Лейбёрну, женившего на ней своего сына.',\n",
       "  0.3497588024421523),\n",
       " ('Кроме того, Клиффорду была поручена опека над Изабеллой, одной из дочерей мятежного барона Роберта де Випонта, на которой он женил своего наследника.',\n",
       "  0.3080062523852433),\n",
       " ('На ближайшие семь лет опекунами короля были назначены сторонники Дорварда, причем сместить их мог только король Англии.',\n",
       "  0.2545444967241659)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('Верный королю барон в награду был назначен опекуном дочери мятежника и женил на ней своего сына')[1][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac2ab9",
   "metadata": {},
   "source": [
    "2) К началу ХХ века на складе казенного чугуноплавильного завода скопился годовой запас продукции  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c940ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: query word {казенный} is not in the collection\n",
      "WARN: query word {скопиться} is not in the collection\n",
      "WARN: query word {запас} is not in the collection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('XX век.', 0.49622824011683675),\n",
       " ('Экономический кризис начала XX века почти не сказался на работе Баранчинского завода, работавшего по государственным заказам.',\n",
       "  0.36536559395037094),\n",
       " ('По инициативе Шувалова Баранчинский завод был реконструирован в чугуноплавильный.',\n",
       "  0.24106812342337336)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('К началу XX века на складе казенного чугуноплавильного завода скопился годовой запас продукции')[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e2f423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: query word {хх} is not in the collection\n",
      "WARN: query word {казенный} is not in the collection\n",
      "WARN: query word {скопиться} is not in the collection\n",
      "WARN: query word {запас} is not in the collection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Экономический кризис начала XX века почти не сказался на работе Баранчинского завода, работавшего по государственным заказам.',\n",
       "  0.25827223250024517),\n",
       " ('По инициативе Шувалова Баранчинский завод был реконструирован в чугуноплавильный.',\n",
       "  0.2577126642065135),\n",
       " ('Но из-за отсутствия сторонних заказов на 1 января 1904 года на складах завода накопилось 698 тыс. пудов товарного чугуна, что превышало его годовую выплавку.',\n",
       "  0.2504244714330281)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('К началу ХХ века на складе казенного чугуноплавильного завода скопился годовой запас продукции')[1][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18818705",
   "metadata": {},
   "source": [
    "3) Лагерь сапёров мог стать важнейшим городом Британской Колумбии  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "340df698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Название провинции было выбрано королевой Викторией, когда колония Британской Колумбии стала британской в 1858 году.',\n",
       "  0.2622196898521864),\n",
       " ('Столица провинции, город Виктория с населением 85 792 человек не входит в число 10 крупнейших городов Британской Колумбии.',\n",
       "  0.23909099746446222),\n",
       " ('Туризм также стали играть важную роль в экономике.', 0.22778274362385423)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('Лагерь сапёров мог стать важнейшим городом Британской Колумбии')[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ab7d048",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Название провинции было выбрано королевой Викторией, когда колония Британской Колумбии стала британской в 1858 году.',\n",
       "  0.2423808893362787),\n",
       " ('Туризм также стали играть важную роль в экономике.', 0.2277827436238542),\n",
       " ('Столица провинции, город Виктория с населением 85 792 человек не входит в число 10 крупнейших городов Британской Колумбии.',\n",
       "  0.21712823838191134)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('Лагерь сапёров мог стать важнейшим городом Британской Колумбии')[1][:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
